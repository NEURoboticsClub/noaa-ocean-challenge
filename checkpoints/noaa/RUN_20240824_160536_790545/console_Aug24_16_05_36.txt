============================================================
New run started at 2024-08-24.16:05:29.578012
sys.argv: "c:\Users\Nikolas Sanderson\Documents\GitHub\Python-Visual\noaa-ocean-challenge\test.py"
============================================================
The console stream is logged into C:\Users\Nikolas Sanderson\sg_logs\console.log

Indexing dataset annotations:   0%|                                                                                                                                                                                                                                                                                                              | 0/453 [00:00<?, ?it/s]
Indexing dataset annotations:  47%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                                         | 213/453 [00:00<00:00, 1977.35it/s]
Indexing dataset annotations:  91%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                         | 414/453 [00:00<00:00, 1989.05it/s]
Indexing dataset annotations: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 453/453 [00:00<00:00, 1976.35it/s]

Indexing dataset annotations:   0%|                                                                                                                                                                                                                                                                                                              | 0/110 [00:00<?, ?it/s]
Indexing dataset annotations: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 110/110 [00:00<00:00, 1905.22it/s]

Indexing dataset annotations:   0%|                                                                                                                                                                                                                                                                                                               | 0/47 [00:00<?, ?it/s]
Indexing dataset annotations: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:00<00:00, 1510.08it/s]
The console stream is now moved to C:\Users\Nikolas Sanderson\Documents\GitHub\Python-Visual\noaa-ocean-challenge/checkpoints\noaa\RUN_20240824_160536_790545/console_Aug24_16_05_36.txt
Object name `linear_epoch_step` is now deprecated. Please replace it with `LinearEpochLRWarmup`.
initialize_param_groups and update_param_groups usages are deprecated since 3.4.0, will be removed in 3.5.0 and have no effect. 
 Assign different learning rates by passing a mapping of layer name prefixes to lr values through initial_lr training hyperparameter (i.e initial_lr={'backbone': 0.01, 'default':0.1})
[2024-08-24 16:05:37] ERROR - sg_trainer_utils.py - Uncaught exception
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "C:\Users\Nikolas Sanderson\AppData\Local\Programs\Python\Python310\lib\multiprocessing\spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "C:\Users\Nikolas Sanderson\AppData\Local\Programs\Python\Python310\lib\multiprocessing\spawn.py", line 125, in _main
    prepare(preparation_data)
  File "C:\Users\Nikolas Sanderson\AppData\Local\Programs\Python\Python310\lib\multiprocessing\spawn.py", line 236, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "C:\Users\Nikolas Sanderson\AppData\Local\Programs\Python\Python310\lib\multiprocessing\spawn.py", line 287, in _fixup_main_from_path
    main_content = runpy.run_path(main_path,
  File "C:\Users\Nikolas Sanderson\AppData\Local\Programs\Python\Python310\lib\runpy.py", line 289, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "C:\Users\Nikolas Sanderson\AppData\Local\Programs\Python\Python310\lib\runpy.py", line 96, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "C:\Users\Nikolas Sanderson\AppData\Local\Programs\Python\Python310\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "c:\Users\Nikolas Sanderson\Documents\GitHub\Python-Visual\noaa-ocean-challenge\test.py", line 142, in <module>
    trainer.train(
  File "C:\Users\Nikolas Sanderson\Documents\GitHub\Python-Visual\noaa-ocean-challenge\.venv\lib\site-packages\super_gradients\training\sg_trainer\sg_trainer.py", line 1480, in train
    first_train_batch = next(iter(self.train_loader))
  File "C:\Users\Nikolas Sanderson\Documents\GitHub\Python-Visual\noaa-ocean-challenge\.venv\lib\site-packages\torch\utils\data\dataloader.py", line 440, in __iter__
    return self._get_iterator()
  File "C:\Users\Nikolas Sanderson\Documents\GitHub\Python-Visual\noaa-ocean-challenge\.venv\lib\site-packages\torch\utils\data\dataloader.py", line 388, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "C:\Users\Nikolas Sanderson\Documents\GitHub\Python-Visual\noaa-ocean-challenge\.venv\lib\site-packages\torch\utils\data\dataloader.py", line 1038, in __init__
    w.start()
  File "C:\Users\Nikolas Sanderson\AppData\Local\Programs\Python\Python310\lib\multiprocessing\process.py", line 121, in start
    self._popen = self._Popen(self)
  File "C:\Users\Nikolas Sanderson\AppData\Local\Programs\Python\Python310\lib\multiprocessing\context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "C:\Users\Nikolas Sanderson\AppData\Local\Programs\Python\Python310\lib\multiprocessing\context.py", line 336, in _Popen
    return Popen(process_obj)
  File "C:\Users\Nikolas Sanderson\AppData\Local\Programs\Python\Python310\lib\multiprocessing\popen_spawn_win32.py", line 45, in __init__
    prep_data = spawn.get_preparation_data(process_obj._name)
  File "C:\Users\Nikolas Sanderson\AppData\Local\Programs\Python\Python310\lib\multiprocessing\spawn.py", line 154, in get_preparation_data
    _check_not_importing_main()
  File "C:\Users\Nikolas Sanderson\AppData\Local\Programs\Python\Python310\lib\multiprocessing\spawn.py", line 134, in _check_not_importing_main
    raise RuntimeError('''
RuntimeError: 
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The "freeze_support()" line can be omitted if the program
        is not going to be frozen to produce an executable.
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "C:\Users\Nikolas Sanderson\AppData\Local\Programs\Python\Python310\lib\multiprocessing\spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "C:\Users\Nikolas Sanderson\AppData\Local\Programs\Python\Python310\lib\multiprocessing\spawn.py", line 125, in _main
    prepare(preparation_data)
  File "C:\Users\Nikolas Sanderson\AppData\Local\Programs\Python\Python310\lib\multiprocessing\spawn.py", line 236, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File "C:\Users\Nikolas Sanderson\AppData\Local\Programs\Python\Python310\lib\multiprocessing\spawn.py", line 287, in _fixup_main_from_path
    main_content = runpy.run_path(main_path,
  File "C:\Users\Nikolas Sanderson\AppData\Local\Programs\Python\Python310\lib\runpy.py", line 289, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "C:\Users\Nikolas Sanderson\AppData\Local\Programs\Python\Python310\lib\runpy.py", line 96, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "C:\Users\Nikolas Sanderson\AppData\Local\Programs\Python\Python310\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "c:\Users\Nikolas Sanderson\Documents\GitHub\Python-Visual\noaa-ocean-challenge\test.py", line 142, in <module>
    trainer.train(
  File "C:\Users\Nikolas Sanderson\Documents\GitHub\Python-Visual\noaa-ocean-challenge\.venv\lib\site-packages\super_gradients\training\sg_trainer\sg_trainer.py", line 1480, in train
    first_train_batch = next(iter(self.train_loader))
  File "C:\Users\Nikolas Sanderson\Documents\GitHub\Python-Visual\noaa-ocean-challenge\.venv\lib\site-packages\torch\utils\data\dataloader.py", line 440, in __iter__
    return self._get_iterator()
  File "C:\Users\Nikolas Sanderson\Documents\GitHub\Python-Visual\noaa-ocean-challenge\.venv\lib\site-packages\torch\utils\data\dataloader.py", line 388, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "C:\Users\Nikolas Sanderson\Documents\GitHub\Python-Visual\noaa-ocean-challenge\.venv\lib\site-packages\torch\utils\data\dataloader.py", line 1038, in __init__
    w.start()
  File "C:\Users\Nikolas Sanderson\AppData\Local\Programs\Python\Python310\lib\multiprocessing\process.py", line 121, in start
    self._popen = self._Popen(self)
  File "C:\Users\Nikolas Sanderson\AppData\Local\Programs\Python\Python310\lib\multiprocessing\context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "C:\Users\Nikolas Sanderson\AppData\Local\Programs\Python\Python310\lib\multiprocessing\context.py", line 336, in _Popen
    return Popen(process_obj)
  File "C:\Users\Nikolas Sanderson\AppData\Local\Programs\Python\Python310\lib\multiprocessing\popen_spawn_win32.py", line 45, in __init__
    prep_data = spawn.get_preparation_data(process_obj._name)
  File "C:\Users\Nikolas Sanderson\AppData\Local\Programs\Python\Python310\lib\multiprocessing\spawn.py", line 154, in get_preparation_data
    _check_not_importing_main()
  File "C:\Users\Nikolas Sanderson\AppData\Local\Programs\Python\Python310\lib\multiprocessing\spawn.py", line 134, in _check_not_importing_main
    raise RuntimeError('''
RuntimeError: 
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The "freeze_support()" line can be omitted if the program
        is not going to be frozen to produce an executable.
